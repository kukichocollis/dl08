{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kukichocollis/dl08/blob/main/project/cifar10/cifar10_DL2_CNN_DataAug_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rswfCVLZ-QW0"
      },
      "source": [
        "# **CNN model of cifar10 dataset**\n",
        "- Conv2D + FCN\n",
        "    * Conv2D : 2차원 합성곱 필터링 + 풀링(Pooling)\n",
        "    - > 2차원 필터로 영상을 대표하는 특징을 추출\n",
        "    * FCN : 1차원 완전연결신경망\n",
        "    - > Conv2D에서 추출된 대표 특징들을 이용하여 FCN으로 최종 학습 완료\n",
        "    * ## **Data augmentation** : 데이터 증대\n",
        "\n",
        "***\n",
        "- ## Traget: **Find the best model** using Data augmentation\n",
        "***\n",
        "\n",
        "![cnn_c4f5.png](https://raw.githubusercontent.com/Redwoods/Py/master//pdm2020/my-note/py-tensorflow/images/cnn_c4f5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yhvkxS_HhpK"
      },
      "source": [
        "## Search the best model of C4F5\n",
        "- callback\n",
        "    - Early stopping\n",
        "    - model checkpoint\n",
        "- Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GgGzPXPVyfa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMZqMpIvIlwf"
      },
      "outputs": [],
      "source": [
        "# import TF2 submodules\n",
        "from tensorflow.keras import layers, models, callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0IOOUM14Jk1"
      },
      "source": [
        "## **데이터 로딩, 정규화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1ogJ7I64Fz-"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train0, y_train0), (X_test0, y_test0) = cifar10.load_data()\n",
        "\n",
        "# Normalization\n",
        "X_train, X_test = X_train0/255.0, X_test0/255.0 # 정규화\n",
        "\n",
        "print(\"X_train={0}\".format(X_train.shape))\n",
        "print(\"y_train={0}\".format(y_train0.shape)) \n",
        "print(\"X_test={0}\".format(X_test.shape))\n",
        "print(\"y_test={0}\".format(y_test0.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F46-QZqJHiQ6"
      },
      "outputs": [],
      "source": [
        "# One-Hot-Encoding\n",
        "# Use function to_categorical() to do One-Hot-Encoding\n",
        "# tf.keras.utils.to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train0, 10)\n",
        "y_test = to_categorical(y_test0, 10)\n",
        "y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ3OfP5PkEkL"
      },
      "outputs": [],
      "source": [
        "# y_train0.shape vs. y_train.shape\n",
        "y_train0.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z7SozStigmF"
      },
      "source": [
        "### Display cifar10 data\n",
        "- one random image\n",
        "- 10 representative images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK7XT3XoirSL"
      },
      "outputs": [],
      "source": [
        "# Code here!\n",
        "# display one random image from the training set:\n",
        "class_names =  ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "idx = np.random.randint(0, X_train0.shape[0])\n",
        "print(idx)\n",
        "image = X_train0[idx]\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(image) #, cmap=plt.get_cmap('gray'))\n",
        "plt.title(class_names[y_train0[idx][0]])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzhD5pcukau7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,5))\n",
        "num0_9 = np.unique(y_train0, return_index=True)[1]\n",
        "images = X_train[num0_9]\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    # num0_9 = X_train0[y_train0 == i]\n",
        "    \n",
        "    # print(num0_9.shape)\n",
        "    # plt.imshow(num0_9[0]) \n",
        "    plt.imshow(images[i])\n",
        "    plt.title(class_names[i])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0FD4XOZas-v"
      },
      "source": [
        "## data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8exLx7IbfXby"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mBn6XkzLImy"
      },
      "outputs": [],
      "source": [
        "# data augmentation\n",
        "# https://github.com/moritzhambach/Image-Augmentation-in-Keras-CIFAR-10-/blob/master/CNN%20with%20Image%20Augmentation%20(CIFAR10).ipynb\n",
        "# set up image augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKwP4jvNkRQI"
      },
      "outputs": [],
      "source": [
        "# Show samples of data generation\n",
        "# Select one sample\n",
        "idx = np.random.randint(0, X_train.shape[0])\n",
        "print(idx)\n",
        "sample = X_train[idx]\n",
        "sample = np.expand_dims(sample, axis=0)\n",
        "\n",
        "image = X_train0[idx]\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(image) #, cmap=plt.get_cmap('gray'))\n",
        "plt.title(class_names[y_train0[idx][0]])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "obj = datagen.flow(sample, batch_size=1)\n",
        "fig = plt.figure(figsize=(11,2))\n",
        "\n",
        "for i in range(8):\n",
        "\tplt.subplot(1,8,i+1)\n",
        "\timage = obj.next()\n",
        "\tplt.imshow(image[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJyaCHrjoD7W"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 50\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=BATCH_SIZE):\n",
        "    print(X_batch.shape, y_batch.shape)\n",
        "    # create a grid of 5x10 images\n",
        "    plt.figure(figsize=(13,10))\n",
        "    for i in range(BATCH_SIZE):\n",
        "        plt.subplot(5,10,i+1)\n",
        "        plt.imshow(X_batch[i]) #, cmap=plt.get_cmap('gray'))\n",
        "        plt.title(class_names[np.argmax(y_batch[i])])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55DYVfFXi0WR"
      },
      "source": [
        "# Design CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPcLIcUCcsiG"
      },
      "source": [
        "### import models, layers, callbacks\n",
        "- models: Sequential\n",
        "- layers: Conv2D, MaxPool2D, Flatten\n",
        "- callbacks: ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bpq3wneB2sbP"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, TensorBoard\n",
        "from keras import regularizers, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeuHLmWo6KWT"
      },
      "outputs": [],
      "source": [
        "# 모델 구성\n",
        "num_classes = 10\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='elu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fmYh1M2cWlC"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 요약 - summary(), plot_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5mfKNADcg_Q"
      },
      "outputs": [],
      "source": [
        "!pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGTiugJtcdJg"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 시각화 - visualkareas.layered_view()\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "# font = ImageFont.truetype(\"arial.ttf\", 36) # windows 10/11\n",
        "font = ImageFont.truetype(\"Humor-Sans.ttf\", 36)  # Linux\n",
        "visualkeras.layered_view(model, \n",
        "                         to_file='./c6f2_daug.png', \n",
        "                         legend=True, spacing=80, font=font, \n",
        "                         scale_xy=5, scale_z=1, one_dim_orientation='x', \n",
        "                         type_ignore=[Activation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaK8ikslcVIb"
      },
      "outputs": [],
      "source": [
        "opt_rms = keras.optimizers.RMSprop(learning_rate=0.001,weight_decay=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fq5VHKI6WyQ"
      },
      "outputs": [],
      "source": [
        "cp_callback = callbacks.ModelCheckpoint(filepath=\"./cifar10_c6f2_Daug_best_weights.{epoch:03d}-{val_accuracy:.4f}.hdf5\", \n",
        "                              monitor='val_accuracy', verbose=0, save_best_only=True)\n",
        "es_callback = callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                            mode='max', verbose=1, patience=5)  # 5, 10, 20, 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms, # 'adam'\n",
        "        metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zaskSbsoyBz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIecn1RJPb1r"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "BATCH_SIZE = 50\n",
        "hist = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE), \n",
        "                 steps_per_epoch=X_train.shape[0]//BATCH_SIZE, \n",
        "                 epochs=epochs, verbose=1, \n",
        "                 callbacks=[cp_callback, es_callback], \n",
        "                 validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0U_Uvr5WqcK"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9EQ2Z_c2gYL"
      },
      "outputs": [],
      "source": [
        "# More graphs of loss and accuracy\n",
        "history_dict = hist.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'go-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'bd', label='Validation Loss')\n",
        "plt.plot(np.argmin(np.array(val_loss))+1,val_loss[np.argmin(np.array(val_loss))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Loss, min: ' + str(np.round(val_loss[np.argmin(np.array(val_loss))],2)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'go-', label='Training Accuracy') #, c='blue')\n",
        "plt.plot(epochs, val_acc, 'bd', label='Validation Accuracy') #, c='red')\n",
        "plt.plot(np.argmax(np.array(val_acc))+1,val_acc[np.argmax(np.array(val_acc))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Accuracy, max: ' + str(np.round(val_acc[np.argmax(np.array(val_acc))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upyGuNJutSvW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z6DJJUCei-s"
      },
      "source": [
        "## **CNN4 + FCN5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSN8pq8DkQ6B"
      },
      "outputs": [],
      "source": [
        "c4f5 = keras.models.Sequential([ \n",
        "    Conv2D(input_shape=(32,32,3), filters= 64, kernel_size=(3,3),strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2), strides=(2,2)), \n",
        "    Conv2D(filters= 128, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Conv2D(filters= 256, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Conv2D(filters= 512, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Flatten(), \n",
        "    keras.layers.Dense(128, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(256, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(512, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(1024, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "c4f5.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eraueiz_iiYQ"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 시각화 - visualkareas.layered_view()\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "# font = ImageFont.truetype(\"arial.ttf\", 24) # windows 10/11\n",
        "font = ImageFont.truetype(\"Humor-Sans.ttf\", 36)  # Linux\n",
        "visualkeras.layered_view(c4f5, \n",
        "                         to_file='./c4f5_daug.png', \n",
        "                         legend=True, spacing=80, font=font, \n",
        "                         scale_xy=5, scale_z=1, one_dim_orientation='x')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw_pQPBdJmU8"
      },
      "outputs": [],
      "source": [
        "cp_callback = callbacks.ModelCheckpoint(filepath=\"./cifar10_c4f5_Daug_best_weights.{epoch:03d}-{val_accuracy:.4f}.hdf5\", \n",
        "                              monitor='val_accuracy', verbose=0, save_best_only=True)\n",
        "es_callback = callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                            mode='max', verbose=1, patience=5)    # patience=10,20,50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94GWWQt-7eRS"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "BATCH_SIZE = 50\n",
        "hist = c4f5.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE), # BATCH_SIZE = 50\n",
        "                 steps_per_epoch=X_train.shape[0]//BATCH_SIZE, \n",
        "                 epochs=epochs, verbose=1, \n",
        "                 callbacks=[cp_callback, es_callback], \n",
        "                 validation_data=(X_test,y_test))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-7is2U49A6Z"
      },
      "outputs": [],
      "source": [
        "c4f5.evaluate(X_test, y_test, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSDQEwojtSvY"
      },
      "outputs": [],
      "source": [
        "# More graphs of loss and accuracy\n",
        "history_dict = hist.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'go-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'bd', label='Validation Loss')\n",
        "plt.plot(np.argmin(np.array(val_loss))+1,val_loss[np.argmin(np.array(val_loss))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Loss, min: ' + str(np.round(val_loss[np.argmin(np.array(val_loss))],2)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'go-', label='Training Accuracy') #, c='blue')\n",
        "plt.plot(epochs, val_acc, 'bd', label='Validation Accuracy') #, c='red')\n",
        "plt.plot(np.argmax(np.array(val_acc))+1,val_acc[np.argmax(np.array(val_acc))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Accuracy, max: ' + str(np.round(val_acc[np.argmax(np.array(val_acc))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBPKMI4y3fsa"
      },
      "source": [
        "## 모형의 저장\n",
        "\n",
        "- 트레이닝이 끝난 모형은 save 메서드로 가중치와 함께 hdf5 형식으로 저장\n",
        "- load 명령으로 불러 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejZevLrZfXb2"
      },
      "source": [
        "### Best Daug model\n",
        "- cifar10_Daug_best_weights.011-0.8137.hdf5\n",
        "- cifar10_Daug_best_weights.028-0.8485.hdf5\n",
        "- cifar10_c6f2_Daug_best_weights.037-0.8499.hdf5\n",
        "- cifar10_c4f5_Daug_best_weights.026-0.7891.hdf5\n",
        "- cifar10_c4f5_Daug_best_weights.035-0.7846.hdf5\n",
        "\n",
        "### Best c4f5 model of cifar10\n",
        "- cifar10_c4f5_best_weights.010-0.7446.hdf5\n",
        "- cifar10_c4f5_best_weights.012-0.7493.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7-ysIVy3fse"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_best = load_model('cifar10_Daug_best_weights.028-0.8485.hdf5')\n",
        "model_best.evaluate(X_test, y_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvp8pY02tSvZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE3BBcU6ECQ8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predictions = model_best.predict(X_test)\n",
        "predictions0 = np.argmax(predictions, axis=1)\n",
        "cm = confusion_matrix(y_test0, predictions0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhhwsbO7FEHN"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, cbar=False, xticklabels=class_names, yticklabels=class_names, fmt='d', annot=True, cmap=plt.cm.coolwarm)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion matrix', fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# New method to plot confusion_matrix\n",
        "#\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# y_pred = mlp.predict(X_test)\n",
        "cm = confusion_matrix(y_test0, predictions0)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm) #, display_labels=mlp.classes_)\n",
        "disp.plot(cmap='Blues')\n",
        "\n",
        "plt.savefig('confusion_matrix.pdf')"
      ],
      "metadata": {
        "id": "ZqLqwGXrGTyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "golg0zIvoAWc"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdFDXGzGtSvZ"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "3834ce636a3ba6c6c2bd8b9b527c48eede78c367f849f6cce666ea7f1d26e2fb"
    },
    "kernelspec": {
      "display_name": "Python 3 (Spyder)",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}